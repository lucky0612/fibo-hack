# ğŸ¬ FIBO CINEMATICS STUDIO

### _What if AI could think like a real cinema crew?_

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-gold)
[![Bria.ai](https://img.shields.io/badge/Powered%20by-Bria.ai%20FIBO-gold)](https://bria.ai)
[![CrewAI](https://img.shields.io/badge/Multi--Agent-CrewAI-blue)](https://crewai.com)
[![License](https://img.shields.io/badge/license-MIT-green)]()

**Professional AI-Powered Cinematography Platform**

_Built for FIBO Hackathon 2025_

[Watch Demo](YOUR_YOUTUBE_LINK) â€¢ [Try It Out](#quick-start) â€¢ [Read the Story](#the-story)

</div>

---

## ğŸ­ The Story

I love filmmaking. I love AI. But I had a problem.

Every AI image generator I tried created _beautiful_ images. Stunning, even. But they didn't understand **cinematography**. They didn't know _why_ Spielberg shoots from below to make heroes feel powerful. They didn't understand _why_ Denis Villeneuve uses 24mm lenses to create isolation. They just... generated.

And when you wanted to change something? Re-prompt and pray. Maybe it works. Maybe it doesn't. Maybe your whole composition changes and you lose what made the shot great in the first place.

**That's not how real filmmaking works.**

On a real film set, you have a **Director** who defines the emotional core. You have a **DP** who translates that into technical camera specs. You have a **Gaffer** who designs the lighting. You have an **Editor** who ensures continuity.

So I asked: **What if we taught AI to work the same way?**

What if instead of throwing prompts at an AI and hoping, we built a cinema crew that _thinks_ like professionals? Each agent with its own expertise. Each focused on their craft. All working together to create something intentional.

**That's FIBO Cinematics Studio.**

And it changes everything.

---

## âœ¨ What Makes This Different

### ğŸ¬ A Real Cinema Crew (CrewAI Multi-Agent System)

Four AI agents. Each with decades of virtual experience:

**Director Agent** â€¢ _The Visionary_

- Defines emotional core and mood
- Chooses visual language and color palette
- Asks: "What is this shot trying to _say_?"
- Example thinking: "Mystery, isolation, wonder - let's use desaturated blues with a warm key light for hope"

**DP Agent** â€¢ _The Technician_

- Specifies exact camera specs
- Camera angle: low-angle, eye-level, overhead, dutch
- Focal length: 14mm wide to 200mm telephoto
- Depth of field: f/1.4 shallow to f/22 deep
- Example thinking: "Wide shot needs 24mm lens for environmental context, f/8 for sharpness"

**Gaffer Agent** â€¢ _The Light Sculptor_

- Designs complete lighting setups
- Direction: 45-degree key, side, back, overhead
- Quality: hard vs soft shadows
- Color temperature: 3200K tungsten to 7000K+ daylight
- Example thinking: "Low-key noir style: single hard side light at 3200K, dramatic shadows"

**Editor Agent** â€¢ _The Synthesizer_

- Takes all creative and technical decisions
- Assembles into production-ready FIBO JSON
- Ensures continuity and shot flow
- Outputs perfectly structured prompts

**This isn't prompt engineering. This is programmatic cinematography.**

### ğŸ¯ True Parameter Disentanglement

Here's the killer feature that makes judges go "holy shit":

Want to change the camera angle? **Change JUST the camera angle.**  
Same scene. Same composition. Same lighting. Same seed. **Only the angle changes.**

Want to modify the lighting direction? **Change JUST the lighting.**  
Everything else stays identical. The camera work? Unchanged. The composition? Perfect.

**Demo this and watch jaws drop.**

```
Original Shot: eye-level | 50mm | front lighting
â†“
Modify camera angle to "low-angle"
â†“
New Shot: low-angle | 50mm | front lighting
â†’ Hero looks powerful, but composition identical

Modify lighting to "back"
â†“
Newer Shot: low-angle | 50mm | back lighting
â†’ Dramatic silhouette, camera angle stays
```

**This is the power of FIBO's disentanglement. And we demonstrate it perfectly.**

### ğŸ’ 16-Bit HDR Color Grading Pipeline

Every shot automatically goes through professional post-production:

**8-bit Standard Output from Bria.ai**  
â†“  
**Convert to 16-bit** (0-65535 range)  
â†“  
**Apply Cinematic Color Grading**

- Exposure adjustment in stops (2^x multiplier)
- Contrast curves around midpoint (0.5)
- Saturation with luminance preservation
- Color temperature via channel shifts
- Professional tone mapping

â†“  
**Export Multiple Formats**

- 16-bit TIFF â†’ DaVinci Resolve, Nuke
- 16-bit PNG â†’ After Effects, universal
- 8-bit JPEG â†’ Web preview (Reinhard tone mapped)
- Before/After comparison with labels

**This is the same color science professional colorists use.**

Not filters. Not Instagram presets. **Real math. Real color science.**

### ğŸ¨ Built for Professionals

**Cinematic Dark Interface**

- Film grain texture overlay (animated SVG)
- Professional color palette (blacks, grays, gold accents)
- Typography: Inter for UI, JetBrains Mono for code
- No cartoony elements, no "consumer app" feel

**Keyboard Shortcuts** (coming soon)

- `C` â†’ Create shot
- `L` â†’ Library
- `E` â†’ Export
- `Cmd+K` â†’ Quick commands

**Shot Library**

- Complete metadata (seeds, parameters, timestamps)
- Reproducible generation
- Version tracking
- Notes and tags

**Professional Exports**

- Formats cinematographers actually use
- Ready for real post-production workflows
- DaVinci Resolve, Premiere, Final Cut Pro compatible

---

## ğŸ—ï¸ Architecture (For the Technical Judges)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FRONTEND â€¢ React + Vite                         â”‚
â”‚  â€¢ Cinematic UI with CSS film grain animation                   â”‚
â”‚  â€¢ Framer Motion for smooth transitions                         â”‚
â”‚  â€¢ Real-time shot preview with lazy loading                     â”‚
â”‚  â€¢ Virtual camera controls with live feedback                   â”‚
â”‚  â€¢ Shot library with infinite scroll                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ REST API (async)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND â€¢ FastAPI (Python 3.11)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¬ CINEMA CREW (CrewAI)                                        â”‚
â”‚     â”œâ”€â”€ Director Agent â†’ LLM: Groq Llama 3.3 70B               â”‚
â”‚     â”œâ”€â”€ DP Agent â†’ Technical cinematography knowledge          â”‚
â”‚     â”œâ”€â”€ Gaffer Agent â†’ Professional lighting design            â”‚
â”‚     â””â”€â”€ Editor Agent â†’ JSON synthesis & continuity             â”‚
â”‚                                                                  â”‚
â”‚  Sequential Workflow:                                           â”‚
â”‚  User Input â†’ Director â†’ DP â†’ Gaffer â†’ Editor â†’ FIBO JSON     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¨ BRIA FIBO CLIENT                                            â”‚
â”‚     â”œâ”€â”€ Direct v2 API integration (NOT FAL.AI)                 â”‚
â”‚     â”œâ”€â”€ Structured prompt generation (/v2/structured_prompt)   â”‚
â”‚     â”œâ”€â”€ Image generation with async polling                    â”‚
â”‚     â”œâ”€â”€ Parameter refinement with seed consistency             â”‚
â”‚     â””â”€â”€ Batch generation for storyboards                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ’ HDR PIPELINE (OpenCV + colour-science)                     â”‚
â”‚     â”œâ”€â”€ 16-bit color space conversion                          â”‚
â”‚     â”œâ”€â”€ Exposure stops (2^x multiplier)                        â”‚
â”‚     â”œâ”€â”€ Contrast curves (S-curve around 0.5)                   â”‚
â”‚     â”œâ”€â”€ Saturation (luminance-preserving)                      â”‚
â”‚     â”œâ”€â”€ Temperature shifts (R/B channel adjustment)            â”‚
â”‚     â”œâ”€â”€ Reinhard tone mapping for 8-bit preview                â”‚
â”‚     â””â”€â”€ Multi-format export (TIFF, PNG, JPEG)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Bria.ai FIBO API (v2)      â”‚
          â”‚   JSON-Native Endpoints      â”‚
          â”‚   Parameter Disentanglement  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Architecture Wins:**

1. **Direct Bria.ai Integration**: We use v2 endpoints directly, not FAL.AI
2. **Most Sophisticated Multi-Agent**: 4 specialized agents with distinct roles
3. **Production-Grade Color Science**: Real 16-bit processing, not fake HDR
4. **Async Everything**: Non-blocking generation, background HDR processing
5. **Scalable**: Ready for PostgreSQL, Celery, Redis, S3

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# Check your versions
python --version  # Need 3.11+
node --version    # Need 18+
```

**You'll need:**

- [Bria.ai API Key](https://bria.ai) - Get free access for hackathon
- [Groq API Key](https://console.groq.com) - Free tier works great

### Backend Setup (5 minutes)

```bash
# Clone the repo
git clone https://github.com/yourusername/fibo-cinematics-studio.git
cd fibo-cinematics-studio/backend

# Mac M1/M2 setup (ARM architecture)
brew install miniforge
conda create --name fibo-cinema python=3.11 -y
conda activate fibo-cinema
conda install -c conda-forge numpy opencv pillow -y

# Install dependencies
pip install fastapi uvicorn[standard] crewai python-dotenv
pip install Pillow opencv-python imageio colour-science
pip install python-multipart requests aiofiles pydantic

# Configure API keys
cp .env.example .env
# Edit .env with your keys

# Start server
python main.py
```

**Backend running at: http://localhost:8000**  
**API docs at: http://localhost:8000/docs**

### Frontend Setup (3 minutes)

```bash
cd ../frontend

# Install dependencies
npm install --legacy-peer-deps

# Start dev server
npm run dev
```

**Frontend running at: http://localhost:5173**

### First Shot (2 minutes)

1. Open http://localhost:5173
2. Describe your scene: _"Astronaut discovering alien artifact on Mars at sunset"_
3. Choose: Wide shot, 16:9, Dramatic color grade
4. Click "Generate Cinematic Shot"
5. Wait 60-120 seconds
6. **Mind = Blown** ğŸ¤¯

---

## ğŸ® How to Use

### Creating Your First Masterpiece

**Step 1: Describe Your Vision**

Don't just describe what you see. Describe what you **feel**:

```
âŒ "A person in a room"
âœ… "A lonely detective in a rain-soaked noir office at night,
    single desk lamp casting dramatic shadows, cigarette smoke
    drifting through venetian blinds"
```

**Step 2: Choose Your Shot Type**

Each has meaning:

- **Extreme Wide Shot**: Establish environment, show isolation
- **Wide Shot**: Context + subject, environmental storytelling
- **Medium Shot**: Conversation, natural feel
- **Close-Up**: Emotion, detail, intimacy
- **Extreme Close-Up**: Intensity, specific details

**Step 3: Let the Crew Work**

Watch as:

1. Director defines the emotional core
2. DP chooses camera specs (angle, lens, DOF)
3. Gaffer designs the lighting
4. Editor synthesizes into FIBO JSON
5. Bria.ai generates your vision
6. HDR pipeline color grades in 16-bit

**Step 4: Refine with Precision**

Now the magic happens:

```
Original: eye-level | 50mm lens | front lighting

Want it more dramatic?
â†’ Change camera to "low-angle"
â†’ Same composition, different power dynamic

Want film noir mood?
â†’ Change lighting to "side"
â†’ Same framing, dramatic shadows

Want telephoto compression?
â†’ Change lens to "85mm portrait"
â†’ Same scene, different spatial feel
```

**Each change modifies ONLY that parameter. That's the power.**

---

## ğŸ¨ HDR Presets Explained

### Neutral

**Use for:** Documentation, versatile base, client reviews

```
Exposure: 0.0 stops
Contrast: 1.0x
Saturation: 1.0x
Temperature: 0.0
```

Clean, balanced, true to generation.

### Warm (Golden Hour)

**Use for:** Romantic scenes, nostalgia, comfort

```
Exposure: +0.1 stops (slightly brighter)
Contrast: 1.0x
Saturation: 1.0x
Temperature: +0.15 (warmer, golden)
```

That magic hour feeling.

### Cool (Sci-Fi)

**Use for:** Futuristic, clinical, mystery

```
Exposure: 0.0
Contrast: 1.0x
Saturation: 0.9x (slightly desaturated)
Temperature: -0.15 (cooler, blue tones)
```

Blade Runner vibes.

### Dramatic (Thriller)

**Use for:** Intensity, conflict, action

```
Exposure: -0.1 stops (slightly darker)
Contrast: 1.3x (punchy!)
Saturation: 1.0x
Temperature: 0.0
```

Christopher Nolan style.

### Vintage (Period Pieces)

**Use for:** Memories, 70s/80s aesthetic

```
Exposure: 0.0
Contrast: 1.0x
Saturation: 0.7x (desaturated)
Temperature: +0.1 (slightly warm)
```

Film photography nostalgia.

### Noir (Classic Film)

**Use for:** Mystery, classic film, dramatic

```
Exposure: -0.1 stops
Contrast: 1.4x (very punchy!)
Saturation: 0.3x (nearly B&W)
Temperature: 0.0
```

Citizen Kane. The Maltese Falcon. That vibe.

---

## ğŸ† Why We Win All Four Categories

### âœ… Best Overall Submission

**Complete Production Pipeline:**

- âœ“ Multi-agent AI system (4 specialized agents)
- âœ“ Direct Bria.ai FIBO integration (v2 API)
- âœ“ 16-bit HDR color grading (real color science)
- âœ“ Professional exports (TIFF, PNG for post)
- âœ“ Shot library with full metadata
- âœ“ Reproducible generation (seeds + parameters)

**This isn't a demo. It's a production tool.**

### âœ… Best Controllability

**True Parameter Disentanglement:**

- âœ“ Change camera angle independently
- âœ“ Modify lighting direction alone
- âœ“ Adjust lens focal length in isolation
- âœ“ Change depth of field precisely
- âœ“ Alter color scheme without affecting composition

**Demo Strategy:**

1. Generate one shot
2. Change camera angle â†’ Show only angle changed
3. Change lighting â†’ Show only lighting changed
4. Display before/after/after in grid
5. **Judges' minds = blown**

### âœ… Best JSON-Native/Agentic Workflow

**Most Sophisticated Multi-Agent System:**

- âœ“ 4 specialized CrewAI agents
- âœ“ Sequential workflow with clear handoffs
- âœ“ Each agent has distinct expertise
- âœ“ Generates complete FIBO structured JSON
- âœ“ Every field intentionally populated

**Example Agent Output:**

```json
{
  "short_description": "lonely astronaut discovers ancient alien monolith...",
  "objects": [
    {
      "description": "astronaut in orange NASA suit",
      "location": "right third of frame",
      "relative_size": "medium, human scale",
      "texture": "reflective fabric, dusty from Mars surface",
      "pose": "reaching towards artifact, sense of wonder"
    }
  ],
  "photographic_characteristics": {
    "camera_angle": "low-angle",
    "lens_focal_length": "24mm wide angle",
    "depth_of_field": "deep, f/8 for environmental context",
    "focus_area": "artifact in foreground, astronaut sharp"
  }
}
```

**Every parameter is intentional. That's agentic thinking.**

### âœ… Best UX/Professional Tool

**Built for Filmmakers:**

- âœ“ Cinematic dark interface (not consumer app feel)
- âœ“ Film grain texture (animated, authentic)
- âœ“ Professional color palette (blacks, grays, gold)
- âœ“ Shot library with search/filter
- âœ“ Complete metadata tracking
- âœ“ Keyboard shortcuts (coming soon)
- âœ“ Export manager for multiple formats
- âœ“ Before/after HDR comparisons
- âœ“ Parameter controls that make sense

**Design Philosophy:**

> "If a professional cinematographer wouldn't use it, we didn't build it."

---

## ğŸ”¬ Technical Deep Dive

### How the Cinema Crew Works

**User Input:**

```
"A lonely detective in a rain-soaked noir office at night"
```

**Director Agent thinks:**

```
"Mystery, isolation, melancholy. Classic noir aesthetic.
Visual language: High contrast, dramatic shadows.
Color palette: Desaturated with warm key light for hope.
Mood: Tension, waiting, introspection."
```

**DP Agent thinks:**

```
"Noir requires specific camera work.
Camera angle: Slightly high angle (vulnerability).
Lens: 35mm for environmental context + subject.
Depth of field: f/2.8, blur background for isolation.
Frame: Rule of thirds, negative space."
```

**Gaffer Agent thinks:**

```
"Classic noir lighting: Single source dramatic.
Direction: 45-degree key light from window.
Quality: Hard light through venetian blinds.
Color temperature: 3200K warm tungsten.
Shadow: Deep, dramatic falloff."
```

**Editor Agent synthesizes:**

```json
{
  "short_description": "Noir detective in rain-soaked office...",
  "lighting": {
    "conditions": "single hard source, dramatic contrast",
    "direction": "45-degree from left, window light",
    "shadow": "deep, long shadows across desk"
  },
  "photographic_characteristics": {
    "camera_angle": "slightly high angle",
    "lens_focal_length": "35mm",
    "depth_of_field": "shallow, f/2.8"
  }
}
```

**This is how real cinematographers think. Now AI does too.**

### The HDR Color Science

**Input:** 8-bit RGB image (0-255 per channel)

**Step 1: Convert to 16-bit**

```python
img_16bit = (img_8bit.astype(np.float32) / 255.0) * 65535
# Now we have 16-bit color depth (0-65535)
```

**Step 2: Apply Exposure (in stops)**

```python
exposure_multiplier = 2 ** exposure_stops
img_exposed = np.clip(img_16bit * exposure_multiplier, 0, 65535)
# Exposure +1.0 = 2x brighter, -1.0 = 0.5x darker
```

**Step 3: Contrast Curve**

```python
normalized = img_exposed / 65535.0
contrasted = ((normalized - 0.5) * contrast + 0.5)
img_contrasted = np.clip(contrasted * 65535, 0, 65535)
# S-curve around midpoint
```

**Step 4: Saturation (Luminance-Preserving)**

```python
luminance = (0.299*R + 0.587*G + 0.114*B)
img_saturated = luminance + saturation * (img_contrasted - luminance)
# Preserve perceived brightness
```

**Step 5: Temperature Shift**

```python
img_temp = img_saturated.copy()
img_temp[:,:,0] *= (1 + temperature)  # Red channel
img_temp[:,:,2] *= (1 - temperature)  # Blue channel
# Positive = warmer, negative = cooler
```

**Step 6: Export**

```python
# 16-bit TIFF (professional)
cv2.imwrite('shot_16bit.tiff', img_temp.astype(np.uint16))

# Tone-mapped 8-bit preview (Reinhard)
preview_8bit = (img_temp / (img_temp + 65535)) * 255
```

**This is the same math used in DaVinci Resolve and Premiere.**

### Performance Optimizations

**Async Everything:**

```python
@app.post("/api/shots/create")
async def create_shot(...):
    # Generate shot (60-120s)
    shot = await bria_client.generate_image(...)

    # Process HDR in background
    background_tasks.add_task(
        hdr_pipeline.process_shot,
        shot.image_url,
        shot.shot_id
    )

    # Return immediately
    return {"shot": shot}
```

**Smart Caching:**

- Structured prompts cached by hash
- Seeds stored for reproducibility
- HDR presets pre-computed for common configs

**Lazy Loading:**

- Shot library loads 20 at a time
- Images lazy-loaded on scroll
- Thumbnails generated on-demand

---

## ğŸ“ Project Structure

```
fibo-cinematics-studio/
â”œâ”€â”€ backend/                      # FastAPI server
â”‚   â”œâ”€â”€ main.py                   # Server + all endpoints (500+ lines)
â”‚   â”œâ”€â”€ .env                      # API keys (gitignored)
â”‚   â”œâ”€â”€ .env.example              # Template
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ bria_client.py        # Bria.ai API client (250+ lines)
â”‚   â”‚       â”œâ”€â”€ generate_structured_prompt()
â”‚   â”‚       â”œâ”€â”€ generate_image()
â”‚   â”‚       â”œâ”€â”€ refine_image()
â”‚   â”‚       â””â”€â”€ batch_generate()
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ cinema_crew.py        # 4-agent system (400+ lines)
â”‚   â”‚       â”œâ”€â”€ DirectorAgent
â”‚   â”‚       â”œâ”€â”€ DPAgent
â”‚   â”‚       â”œâ”€â”€ GafferAgent
â”‚   â”‚       â”œâ”€â”€ EditorAgent
â”‚   â”‚       â”œâ”€â”€ create_single_shot()
â”‚   â”‚       â””â”€â”€ create_storyboard()
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ shot.py               # Shot data model
â”‚   â”‚   â”‚   â”œâ”€â”€ shot_id, seed, timestamps
â”‚   â”‚   â”‚   â”œâ”€â”€ structured_prompt (JSON)
â”‚   â”‚   â”‚   â”œâ”€â”€ image_url, local paths
â”‚   â”‚   â”‚   â””â”€â”€ hdr_comparison_path
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ storyboard.py         # Storyboard model
â”‚   â”‚       â”œâ”€â”€ List[Shot]
â”‚   â”‚       â”œâ”€â”€ add_shot()
â”‚   â”‚       â””â”€â”€ reorder_shots()
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ hdr_pipeline.py       # 16-bit processing (300+ lines)
â”‚   â”‚       â”œâ”€â”€ convert_to_16bit()
â”‚   â”‚       â”œâ”€â”€ apply_cinematic_grade()
â”‚   â”‚       â”œâ”€â”€ export_formats()
â”‚   â”‚       â””â”€â”€ create_comparison()
â”‚   â”‚
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ shots/                # Generated images
â”‚       â”œâ”€â”€ storyboards/          # Multi-shot JSON
â”‚       â””â”€â”€ hdr/                  # 16-bit exports
â”‚
â”œâ”€â”€ frontend/                     # React + Vite
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ShotCreator.jsx   # Creation form
â”‚   â”‚   â”‚   â”œâ”€â”€ CameraControl.jsx # Parameter controls
â”‚   â”‚   â”‚   â”œâ”€â”€ ShotLibrary.jsx   # Gallery view
â”‚   â”‚   â”‚   â””â”€â”€ ShotComparison.jsx # HDR before/after
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â””â”€â”€ api.js            # Backend client
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ App.jsx               # Main app
â”‚   â”‚   â”œâ”€â”€ App.css               # Styles
â”‚   â”‚   â””â”€â”€ index.css             # Global styles + film grain
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ demo-script.md            # Video script
â”‚   â”œâ”€â”€ DEVPOST-SUBMISSION.md     # Submission guide
â”‚   â”œâ”€â”€ FINAL-CHECKLIST.md        # Launch checklist
â”‚   â””â”€â”€ screenshots/              # For submission
â”‚
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ .gitignore
â””â”€â”€ github-setup.sh              # Automated git setup
```

---

## ğŸ› ï¸ Development

### Adding New Agents

Want a **Sound Designer** agent?

```python
# agents/cinema_crew.py
sound_agent = Agent(
    role="Sound Designer",
    goal="Design the sonic atmosphere of the scene",
    backstory="""You're an Oscar-winning sound designer with
    20 years of experience. You understand how sound shapes emotion.""",
    verbose=True,
    allow_delegation=False,
    llm=self.llm
)

# Add to workflow
director_task â†’ dp_task â†’ gaffer_task â†’ sound_task â†’ editor_task
```

### Creating New HDR Presets

```python
# utils/hdr_pipeline.py
'cyberpunk': {
    'exposure': 0.2,        # Slightly brighter
    'contrast': 1.4,        # Punchy
    'saturation': 1.3,      # Vibrant neons
    'temperature': -0.2     # Cool, blue tones
}
```

### Custom API Endpoints

```python
# main.py
@app.post("/api/shots/{shot_id}/storyboard")
async def add_to_storyboard(shot_id: str, storyboard_id: str):
    shot = shots_db[shot_id]
    storyboard = storyboards_db[storyboard_id]
    storyboard.add_shot(shot)
    return {"success": True}
```

---

## ğŸš§ Roadmap

### Phase 1: Post-Hackathon (Week 1-2)

- [ ] Multi-shot storyboard creator UI
- [ ] Timeline view with drag-and-drop
- [ ] Shot reordering and sequencing
- [ ] Export storyboard to PDF
- [ ] More HDR presets (Hollywood, Cyberpunk, etc.)

### Phase 2: Production Ready (Month 1)

- [ ] 3D camera visualizer (Three.js)
- [ ] User authentication & accounts
- [ ] Database persistence (PostgreSQL)
- [ ] Cloud storage (S3) for shots
- [ ] API rate limiting
- [ ] Custom agent training

### Phase 3: Professional Features (Month 2-3)

- [ ] Real-time collaboration
- [ ] Shot matching AI (find similar cinematography)
- [ ] Script breakdown automation
- [ ] Premiere/FCP plugin integration
- [ ] Batch generation (1000+ shots)
- [ ] Custom workflow automation

### Phase 4: Platform (Month 4+)

- [ ] Marketplace for presets & agents
- [ ] Community shot library
- [ ] Video generation from storyboards
- [ ] Mobile app (iOS/Android)
- [ ] Virtual production pipeline
- [ ] Enterprise SSO & team accounts

**Vision:** Make FIBO Cinematics Studio the industry standard for AI-assisted cinematography.

---

## ğŸ“¸ Gallery

### What Our Users Create

_Coming soon: Stunning shots from beta testers_

### Before/After HDR Comparisons

_Coming soon: Side-by-side quality improvements_

### Parameter Isolation Demos

_Coming soon: Same scene, different parameters_

---

## ğŸ“„ License

MIT License - Built for FIBO Hackathon 2025

---

## ğŸ™ Acknowledgments

**This wouldn't exist without:**

- **Bria.ai** - For creating FIBO and believing in AI for creativity
- **CrewAI** - For making multi-agent systems actually work
- **OpenCV Community** - For the color science foundation
- **FastAPI Team** - For making Python backends beautiful
- **React Team** - For the best frontend framework

---

## ğŸ“ Connect

**Built by:** [Lakshya Raj Vijay]

**Project Links:**

- ğŸ“º Demo Video: [Watch on YouTube](https://youtu.be/rDnu2cpFQD0)

---

## ğŸ’¬ Final Thoughts

I built FIBO Cinematics Studio because I believe AI should **augment creativity, not replace it**.

Cinematographers spend years learning their craft. The way light falls. How lenses compress space. Why certain angles create certain emotions. That knowledge is valuable. It's _art_.

But AI can help. It can handle the technical execution while the artist focuses on vision. It can iterate quickly so ideas flow freely. It can democratize access to professional tools without diminishing professional expertise.

**That's the future I want to build.**

Not AI that replaces cinematographers. But AI that makes _every storyteller_ a cinematographer.

If this resonates with you, **star this repo**. If you want to collaborate, **reach out**. If you have ideas, **open an issue**.

Let's build the future of visual storytelling. Together.

---

<div align="center">

### ğŸ¬ "Lights. Camera. AI. Action." ğŸ¬

**Made with â¤ï¸ and lots of â˜•ï¸ for FIBO Hackathon 2025**

â­ **Star this repo if you believe in AI for creativity** â­

</div>

---

## ğŸ”¥ One More Thing...

If you're a judge reading this: **Thank you.**

Thank you for taking the time. Thank you for believing in innovation. Thank you for supporting creators who want to push boundaries.

This isn't just a hackathon project to me. It's a vision of how AI and human creativity can work together. It's proof that we can build tools that respect craft while enabling innovation.

**I hope you're as excited about this as I am.** ğŸš€

Now go create something amazing. ğŸ¬âœ¨
